{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bruno Lucian_CasafariTest_DataScientist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/brunolucian/DS_teste/blob/master/Bruno_Lucian_CasafariTest_DataScientist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6mEGUK7rYoRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Casafari Take-Home Challenge\n",
        "\n",
        "### Personal Identification\n",
        "Fill here your personal information to accelerate the assessment by our team:\n",
        "* Bruno Lucian Gonçalves da Costa;\n",
        "* Link to your Git and LinkedIn profile;\n",
        "* Seniority level and years of experience;\n",
        "* Position you applied for and the desired scope of tasks in the 1st year, 2nd year, split by years;\n",
        "* Salary expectations in the 1st year, 2nd year (gross per annum, split by years.)\n",
        "\n",
        "### General Information\n",
        "\n",
        "The test is split in three parts and it was designed to give you a complete, yet short, overview of some our daily activities as data scientist at Casafari. \n",
        "\n",
        "The first two parts (Data Extraction and Data Querying) are straightforward and each one is worth 25% of the overall score. The last part , worth 50% of the overall score, is more open-ended and meant to stretch your data science knowledge. Each section has one extra challenge. They are not mandatory nor counted in the general score, but if you have time, they are the chance to impress us with your extraordinary skills.\n",
        "\n",
        "### Guidelines\n",
        "* We expect that the test should take around 6 hours to do. However, we strongly advise you to carefully read this assignment, think about approaches and try to understand the data before diving into the questions. You are free to spend as much time on it as you want, within the timeframe given by our recruiter.\n",
        "* **You can complete this assignment working on this Google Colab, or if you prefer you can use download it and use it as standalone jupyter notebook and send them back to us together with the relevant files.**\n",
        "* In case of using this Google Colab, you'll need to download those files in [this link](https://drive.google.com/open?id=1GvESbHspNnPhRBGt-FWEG5eOWA1Pdckp) and upload it on this notebook running the cell below.\n",
        "* If you want to use some python packages that are not yet installed on this notebook, use !pip install package."
      ]
    },
    {
      "metadata": {
        "id": "wn82o9okMFJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "98bc57b3-81ed-4d22-eafb-2dab73012875"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload('/')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d3831cc-b53a-41e9-af71-6adc6e43f6f4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3d3831cc-b53a-41e9-af71-6adc6e43f6f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-72edf3658aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m   result = output.eval_js(\n\u001b[1;32m     61\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 62\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read property '_uploadFiles' of undefined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LFt-L95GUIbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UDiMNE4NdJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16976948-c26a-480f-c388-f31061456a6b"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "agents.csv  listing.html  properties.csv  sample_data  sample.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LT_oz7zmYwoL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Extraction (CSS + REGEX)\n",
        "\n",
        "Casafari tracks the entire real estate market by aggregating properties from thousands of different websites. The first step of this process is to collect all the relevant information using web crawlers. This task will give a brief overview of how this extraction is made. \n",
        "\n",
        "The task consists of 3 parts, which will evaluate your skills in CSS3 selectors and regular expressions knowledge, which are essential to data extraction processes. We believe that even if you do not have previous knowledge of CSS, HTML and REGEX, you should be able to complete this task in less than a hour. There are many tutorials and informations on how to use CSS3 selectors and regular expressions to extract data. Do not be afraid to google it! This task is also a evaluation of your learning capabilities.\n",
        "\n",
        "The normal questions already have some examples and can be solved only by filling the CSS3 selectors or the regular expressions in the given space. You can check if you have the correct results by running the pre-made script after it. However, if you feel comfortable, you can use another python package and rewrite the script in a similar way to extract the data.\n",
        "\n",
        "For the extra challenges, you'll need to construct the scripts from scratch."
      ]
    },
    {
      "metadata": {
        "id": "D58kOtOXjrR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(1)__ For the following task, use the _listing.html_ file, which represents a listings for a property. Open the HTML file on your browser, investigate it with the Inspect tool, view the source code and explore it. \n",
        "After that, fill the CSS3 selectors in the following script to extract the following information about this property:\n",
        "\n",
        "* Number of bathrooms\n",
        "* Number of bedrooms\n",
        "* Living Area\n",
        "* Energy Rating\n",
        "* Description\n",
        "* Agent Name\n",
        "* Extract the location of the property"
      ]
    },
    {
      "metadata": {
        "id": "_ubceG6_rEek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "46866780-f061-409f-b8c0-25ac50c6fe94"
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "!pip install cssselect"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lxml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: lxml\n",
            "Successfully installed lxml-4.2.5\n",
            "Collecting cssselect\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: cssselect\n",
            "Successfully installed cssselect-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cqba2Ye43Hyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EXAMPLE SELECTOR TO EXTRACT THE PROPERTY TYPE\n",
        "Selector_Example = \"h1.lbl_titulo\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UYR51QwrYWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3483a217-6e9f-45e5-dc7c-1df5b560099e"
      },
      "cell_type": "code",
      "source": [
        "# EXAMPLE CODE, RUN TO CHECK THE EXAMPLE SELECTOR \n",
        "\n",
        "from lxml import html,etree\n",
        "\n",
        "with open(r'listing.html', \"r\") as f:\n",
        "    page = f.read()\n",
        "tree = html.fromstring(page)\n",
        "\n",
        "print('Example -> Property type: {}'.format(tree.cssselect(Selector_Example)[0].text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2e17da7d640b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlxml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'listing.html'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listing.html'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "M7MJswrmP89Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that you understand the example, just fill the CSS selectors here and check it by running the below cells:"
      ]
    },
    {
      "metadata": {
        "id": "o-2ra_gioTOy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############## Q1 ANSWERS ##################\n",
        "Selector_1 = \"WRITE SELECTOR HERE\"\n",
        "Selector_2 = \"WRITE SELECTOR HERE\"\n",
        "Selector_3 = \"WRITE SELECTOR HERE\"\n",
        "Selector_4 = \"WRITE SELECTOR HERE\"\n",
        "Selector_5 = \"WRITE SELECTOR HERE\"\n",
        "Selector_6 = \"WRITE SELECTOR HERE\"\n",
        "Selector_7 = \"WRITE SELECTOR HERE\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AaJuBU1nqsub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### RUN TO CHECK YOUR ANSWERS ##################\n",
        "print('Bathrooms: {}'.format(tree.cssselect(Selector_1)[0].text))\n",
        "print('')\n",
        "print('Bedrooms: {}'.format(tree.cssselect(Selector_2)[0].text))\n",
        "print('')\n",
        "print('Total area: {}'.format(tree.cssselect(Selector_3)[0].text))\n",
        "print('')\n",
        "print('Living area: {}'.format(tree.cssselect(Selector_4)[0].text))\n",
        "print('')\n",
        "print('Description: {}'.format(tree.cssselect(Selector_5)[0].text))\n",
        "print('')\n",
        "print('Agent name: {}'.format(tree.cssselect(Selector_6)[0].text))\n",
        "print('')\n",
        "print('Location: {}'.format(tree.cssselect(Selector_7)[0].text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__U3ndDeRbt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Extra Challenge 1__:\n",
        "\n",
        "Write from scratch a script to extract and print:\n",
        "* One link that leads to http://mydomain.com/link-to-image\n",
        "* Extract all the features of the property"
      ]
    },
    {
      "metadata": {
        "id": "iLmuSkUFR-LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CX07lJog1Jv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(2)__ In the second part you will still have to use the html file. However, this time, you should use regular expressions to extract the following data from the webpage:\n",
        "\n",
        "* Urls that are links to listings (i.e.: http://mydomain.com/link-to-listing). Do not use the whole url itself in regular expression. It should select only 3 links.\n",
        "* The agent telephone number\n",
        "* The property price"
      ]
    },
    {
      "metadata": {
        "id": "ANpQ4SvPSvpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REGEXP EXAMPLE TO EXTRACT THE AGENT EMAIL\n",
        "Regexp_Example = r\"\\\">(.*?@.*?)<\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mPc9TCF2jOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RUN TO CHECK THE EXAMPLE RESULTS\n",
        "import re\n",
        "\n",
        "with open(r'listing.html', \"r\") as f:\n",
        "    page = f.read()\n",
        "\n",
        "print(\"Email extracted: {}\".format(re.findall(Regexp_Example, page)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6z_yGAIm8uyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR REGULAR EXPRESSIONS HERE\n",
        "Regexp_1 = r\"WRITE REGEXP HERE\"\n",
        "Regexp_2 = r\"WRITE REGEXP HERE\"\n",
        "Regexp_3 = r\"WRITE REGEXP HERE\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRZMlLL8r0Pc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### RUN TO CHECK YOUR ANSWERS ##################\n",
        "print('Links extrated:')\n",
        "for w in re.findall(Regexp_1, page):\n",
        "  print(w)\n",
        "print('')\n",
        "print(\"Agent Phone Number: {}\".format(re.findall(Regexp_2, page)[0]))\n",
        "print('')\n",
        "print(\"Property price: {}\".format(re.findall(Regexp_3, page)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o4DbKPVDSk8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Extra Challenge 2:__\n",
        "* Extract latitude and longitude value from html ()_those values are in the html code, but are not shown on the page__)"
      ]
    },
    {
      "metadata": {
        "id": "o5AylkERSo6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxAqykAnY22Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(3)__ For the last task,  use the *sample.json* file. This file contains JSON that has a list of objects inside. Open the file in a code editor, try to identify some pattern on it and check it's structure first. Each object is under unique ID: \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "{ \n",
        "\n",
        "\"SV350\": { ... // data, describing the object ... }, \n",
        "\n",
        "\"fKDFI3\": { ... // data, describing the object ... },\n",
        "\n",
        "...\n",
        "\n",
        "\"38shF\": { ... // data, describing the object ... } \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Therefore, you need to write one regular expression to extract the following information:\n",
        "* Every unique ID on this file (for example, the first unique ID should be NC065 and the last should be NN574). \n",
        "\n",
        "Hint: The length of your list should be 211"
      ]
    },
    {
      "metadata": {
        "id": "VPI6oVuXURc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR REGULAR EXPRESSION HERE\n",
        "Regexp_JSON = r\"WRITE REGEXP HERE\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sa6N56T4kBx7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(r'sample.json', \"r\") as f:\n",
        "    json = f.read()\n",
        "\n",
        "print('----- Expressions extracted -----')\n",
        "print(\"First unique id: {}\".format(re.findall(Regexp_JSON, json)[0]))\n",
        "print(\"Last unique id: {}\".format(re.findall(Regexp_JSON, json)[-1]))\n",
        "print(\"Length of list of unique ids: {}\".format(len(re.findall(r\"\\\"\\w+\\\"(?=:{\\\"o.*?)\", json))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yL20DRtYTuc3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extra Challenge 3:**\n",
        "* Extract all unique IDs that has the expression _\"land\":\"ESP\"_ inside (for example, the object SV350 has this expression inside it)."
      ]
    },
    {
      "metadata": {
        "id": "3waNjkEUTr_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwNzVMIwadT-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Querying (SQL)\n",
        "\n",
        "You have now collected the data, and cleaned it. It was published in Casafari database and you have to query the data in order to prepare it for analysis. You also want to get some initial metrics.\n",
        "\n",
        "To solve this problem consider the data set provided in _properties.csv_ and _agents.csv_ to test your queries.\n",
        "\n",
        "As before, please fill in your queries in the cells provided (double click the blank cells to fill them in).\n",
        "\n",
        "###Schemas:\n",
        "- PROPERTIES table: \n",
        "  - **id**(PK, INT) - unique identification number of the property ad listing\n",
        "  - **title**(VARCHAR) - title of the property ad listing\n",
        "  - **features**(VARCHAR) - field with additional characteristics of the property ad listing\n",
        "  - **living_area**(FLOAT) - living area of the property in square meters\n",
        "  - **total_area**(FLOAT)- total area of the property in square meters\n",
        "   - **plot_area**(FLOAT) - plot area of the property in square meters\n",
        "  - **price**(FLOAT) - selling price of the property in euros\n",
        "  - **agent_id**(INT) - selling agent id\n",
        "  - **createdAt**(DATE) - date in which the property was added to the market\n",
        "- AGENTS table: \n",
        "  - **agent_id**(PK, INT) - selling agent id\n",
        "  - **company**(VARCHAR) - company for which the agent works\n",
        "\n",
        "###Details of properties:\n",
        "- **locations** can be: Alenquer, Quinta da Marinha, Golden Mile, Nagüeles;\n",
        "- **types** can be: ‘apartment’, ‘penthouse’, ‘duplex’, ‘house’, ‘villa’, ‘country estate’,\n",
        "‘moradia', ‘quinta', ‘plot’, ‘land’; \n",
        "- the property types can be part of the following **property groups**:\n",
        "  1. group **‘apartments’** includes types ‘apartment’, ‘penthouse’, ‘duplex’;\n",
        "  2. group **‘‘houses’**‘ includes types ‘house’, ‘villa’, ‘country estate’, ‘moradia', ‘quinta’;\n",
        "  3. group **‘‘plots’**‘ includes types ’plot’, ‘land’.\n",
        "- areas:\n",
        " - for the group **‘plots’** use **plot_area**;\n",
        " - for groups **‘apartments’** and **‘houses’** use the highest value between **total_area** or **living_area**;\n",
        "\n",
        "\n",
        "###Questions:\n",
        "- (Q1) Write a query to extract only listings with a property type “quinta” or “house”;\n",
        "- (Q2) Write a query to extract only listings of properties with a pool;\n",
        "- (Q3) Write a query calculating the average price per square meter of all apartments in Nagüeles.\n",
        "- (Q4) Write a query to identify top 3 companies with largest amount of properties\n",
        "- (Q5) Identify top 3 agents by number of properties within each company\n",
        "\n",
        "\n",
        "####HINT:\n",
        "- Check the csv for these 2 parts. Location names and property type can be found within the title. Be aware of possible traps.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZMiufR188DzQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 1:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "SELECT *\n",
        "FROM _______\n",
        "WHERE _______;\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "RB-PnF489SmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 2:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "lgzd0mTe9U9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 3:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "aO_r3o7a9W0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 4:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Kp0_Ugcs9Y-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 5:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "_b76pb1YYc5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extra challenge 4:**\n",
        "- (Q6) Write a query to identify companies with most expensive properties for each month in 2017\n",
        "- (Q7) Write a query to get first and last property posted by each company"
      ]
    },
    {
      "metadata": {
        "id": "LvSED0f19anR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 6:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "bz3NC48O9cfa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 7:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "D6n6ZF7VahF3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Analysis (Python)\n",
        "\n",
        "\n",
        "You obtained all the data that you need and you now need to run an analysis on the following problem. For this part, feel free to use as many cells as you need below this point. Please use properties.csv as your data source.\n",
        "\n",
        "\n",
        "\n",
        "## Problem \n",
        "A private investor is planning an investment in one of the four locations. In order to decide where to invest he needs to know the price impact of such features as ‘pool’, ‘sea view’ and ‘garage’ on properties in each location.\n",
        "He also asks for the mean price of the properties in each type group (‘apartments’, ‘houses’, ‘plots’) and wants to know about properties in the market that are undervalued and overvalued. In order to accomplish the problem that was described we want you to cover the following steps:\n",
        "\n",
        "####Part 1: Data Cleaning\n",
        "As you have seen previously, a lot of information is present in the title/features fields. From there, we want to extract the relevant information for further analysis, such as:\n",
        " - 1A: Property  **type** (as presented in **Details** above, described in the SQL section) of each property from **title** field\n",
        " - 1B: Property **location** (as presented in **Details** above, described in the SQL section) of each property from ** title** field\n",
        " - 1C: From ** features** field, if a property has:\n",
        "  - a pool\n",
        "  - a garage\n",
        "  - sea view\n",
        "\n",
        "####Expected Outcome for Part 1:\n",
        "- Create a property dataset with the following schema and save it in a csv file:\n",
        "  - id; \n",
        "  - location name\n",
        "  - type\n",
        "  - title\n",
        "  - features\n",
        "  - pool (0/1)\n",
        "  - sea view (0/1)\n",
        "  - garage (0/1)\n",
        "- Pool, sea view and garage should be binary:1 if the property has the feature and 0 if not\n",
        "- For each of the 3 tasks (1A, 1B, 1C), describe in detail the what you did. What are the advantages and disadvantages of your approach?\n",
        "-  Please provide your code in the cells below, in a reproducible and understandable way;"
      ]
    },
    {
      "metadata": {
        "id": "SEbVdIgUv0Qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WS_0w3NAXTZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Part 2: Identify outliers\n",
        "Now that the data is structured correctly, let's look at which properties are a  good deal for our investor. For this you will need to identify undervalued, overvalued, and normal properties in the dataset. Please use any model you find appropiate in order to obtain this.\n",
        "####Expected Outcome for Part 2:\n",
        "- As before, deliver a csv file with the following format:\n",
        "  - id\n",
        "  - location name\n",
        "  - type\n",
        "  - area\n",
        "  - price\n",
        "  - over-valued (0/1)\n",
        "  - under-valued (0/1)\n",
        "  - normal (0/1)\n",
        "- the new columns should be binary, where for example **over-valued** column would get value 1 if the property is indeed over-valued, 0 otherwise;\n",
        "- A short report (could be a pdf file or new cells within the notebook) containing:\n",
        "  - visualizations (such as scatter plots) discriminating between the undervalued, overvalued and normal properties;\n",
        "  - a explanation of what is the difference between under-valued/over-valued properties and pure data outliers;\n",
        "  - any notes/conclusions you wish to add;\n",
        "- Provide your code in a reproducible way in the cells below;"
      ]
    },
    {
      "metadata": {
        "id": "_m0oYlVUXWqI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Part 3: Theoretical questions\n",
        "- Mention at least 2 hidden traps you found while solving the problems and what would help you to clean the data set;\n",
        "- Describe in detail how you would evaluate the price impact of features such as sea view, pool and garage considering the dataset provided. Your answer should also include how would you deal with missing values, outliers and duplicated listings (same property listing published by different agencies);\n"
      ]
    },
    {
      "metadata": {
        "id": "pRh5IOYBvzic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEJZaN7uXaJ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Extra challenge 5:\n",
        "- Describe how would you model the data over time (using createdAt field). What changes over time would you look for and what would you expect the outcomes to be? (i.e. in terms of pricing per location/type)"
      ]
    }
  ]
}